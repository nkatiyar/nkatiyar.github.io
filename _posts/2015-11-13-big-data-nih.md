---
layout: blogpost
title: Blog
desc: Read about our day-to-day activities
post_title: NIH's Big Data Push
author: John Pearson
category: blog
---

<img class="img-responsive" src="http://people.duke.edu/~jmp33/assets/bd2k.png" width="90%"> 

> Big data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so everyone claims they are doing it...
>
> &mdash; Dan Ariely

Phil Bourne is on a mission. [Phil](http://www.sdsc.edu/~bourne/) is the Associate Director for Data Science at the National Institues of Health, and he has only a few years to prove to the biomedical research community that picking its pocket to pay programmers, statisticians, and data curators is not a huge boondoggle, but a bold way forward for science.

Yesterday and today, Phil has been preaching to the choir. I'm sitting in an auditorium at NIH holding somewhere in the neighborhood of 400 people, and even for a group of scientists, it's astonishing how many people are staring at laptop screens. But it's what's on those screens that's really different: GitHub, Sublime Text, Atom, RStudio. These are data people &mdash; correction, *we* are data people &mdash; and it's all hands on deck for the [Big Data To Knowledge Initiative](https://datascience.nih.gov/bd2k) meeting.

What does this mean? A lot of discussion about curation, metadata and standards. Lots of centers and centers to coordinate centers. Money to train people. What does it mean for neuroscience, where our "big" data is not so big by the standards of genomics? Probably not much in the short term, but in the long term, a few changes are clearly on the horizon:

1. Yes, you are going to have to share your data. And you're going to have to make sure it's usable.

1. People here are serious, really serious, about moving to some sort of preprint server model for knowledge dissemination.

I would argue this is a good thing. It's [what we do anyway](https://github.com/pearsonlab). But as so many have pointed out over the last couple of days, the real problems with this sort of change are cultural, not technical. And they run deep:

- The incentive structure in research is a bad fit for the new data ecosystem. We don't credit researchers for software, let alone data management. Worse, there is no career path for our really good scientific programmers and team scientists. We are losing our best people because they do not fit easily into traditional faculty research categories.

- Biomedical scientists work like artisans. We (I do still run some experiments) invest in our data, we sweat for our data, and so we guard our data. We have a natural distrust of computational types, who have shorter, smaller projects and want to pillage our life's work for abstruse ideas we don't understand.

I am personally optimistic that both of these are going to change. At P[&lambda;]ab, we have a diverse and wonderful group of [collaborators](http://pearsonlab.github.io/people.html). But I suspect these issues of culture and trust are primarily sociological, and so it's up to us, to the quants, to show the rest of our colleagues that we can provide real breakthroughs. That data tools really do make better science.

The NIH is giving us a few short years to prove that Big Data is more than hype. We're going to need every bit of that time, a lot of help, and a lot of friends in the experimental world, helping us formulate the questions.

It's going to be an exciting time.

---

PS: I presented a [poster](http://people.duke.edu/~jmp33/assets/bd2k_2015.pdf) on my work with [Jeff Beck](https://www.neuro.duke.edu/research/faculty-labs/beck-lab) on inferring features in complex scenes from neural responses.

Please note: This work is preliminary. Code is not yet up and results may change.